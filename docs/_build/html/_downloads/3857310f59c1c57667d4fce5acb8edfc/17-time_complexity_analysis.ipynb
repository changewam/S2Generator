{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Time Complexity Analysis for The $S^2$ Data Generation\n\nIn this section, we provide a detailed analysis and proof of the time complexity of the $S^2$ data generation mechanism. Our theoretical analysis shows that the time complexity of data generation is proportional to the length $L$ of the time series. We will then verify the specific time required for data generation using multiple sets of different lengths to validate our theoretical analysis.\n\nWe define the specific symbol explanation and its  as follows. Then we use the divide-and-conquer approach to analyze the complexity of our $S^2$ data generation mechanism.\n\n+-----------+----------------------------------------------------------------------+\n| symbol    | explanation                                                          |\n+===========+======================================================================+\n| $L$ | The length of time series                                            |\n+-----------+----------------------------------------------------------------------+\n| $M$ | Number of input channels                                             |\n+-----------+----------------------------------------------------------------------+\n| $N$ | Number of output channels                                            |\n+-----------+----------------------------------------------------------------------+\n| $k$ | Total number of mixed distributions used                             |\n+-----------+----------------------------------------------------------------------+\n| $p$ | Autoregressive model order in ARMA model                             |\n+-----------+----------------------------------------------------------------------+\n| $q$ | Moving average model order in ARMA model                             |\n+-----------+----------------------------------------------------------------------+\n| $P$ | Probability of choosing a sampling method                            |\n+-----------+----------------------------------------------------------------------+\n| $b$ | Number of binary operators used to construct symbolic expressions    |\n+-----------+----------------------------------------------------------------------+\n| $u$ | The number of unary operators used to construct symbolic expressions |\n+-----------+----------------------------------------------------------------------+\n \n1. **Symbolic Expression Generation**: We construct symbolic expressions using a tree structure as a medium. When we have $b$ binary operators, we further insert $(b + 1)$ leaf nodes (the process from (a) to (b) in **Figure 3** in our paper). Therefore, after inserting $u$ unary operators (**Figure 3** (c)), the total number of nodes in the tree is $n = 2b + u + 1$. Because there are many ways to construct a tree, we consider the time complexity of constructing a balanced tree. Therefore, for $N$ symbols constructed, the specific complexity of this process is:\n\n\\begin{align}O(N\\times n\\mathrm{log}n)\\end{align}\n\n\n2. **Sampling series generation**: When we want to generate a sampling time series with $M$ channels, each channel has a probability of :math`:`P` to be sampled using a mixture distribution and a probability of $(1-P)$ to be sampled using an ARMA model. When the sampling length of the series is $L$, the complexity of generating $k$ mixture distribution and ARMA ($p$, $q$) series is $O(kL)$ and $O(L(p+q))$. Therefore, the time complexity of this process can be quantified as:\n\n\\begin{align}O \\left ( ML \\times [Pk + (1-P)(p+q)] \\right )\\end{align}\n\n\n3. **Sampling through symbolic expressions and series**: We simplify the specific operational details of this process and only consider the time complexity of operations with variables. For a series of length L, we have $N$ symbolic expressions to be sampled, and each symbol has an average of $\\frac{M+1}{2}$ variables (Each symbolic expression may contain any number of variables from 1 to M, so here we take $\\frac{M+1}{2}=\\frac{(1+2+\\cdots+M)}{M}$ as the average probability). Then the process can be quantified as:\n\n\\begin{align}O(N \\cdot \\frac{M+1}{2}\\cdot L)\\end{align}\n\nTo sum up, since other variables that affect the $S^2$ sampling process are usually small, it can be intuitively understood that the time complexity of the entire sampling process is proportional to the length $L$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom S2Generator import Generator, SymbolParams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following experiment, we generate time series data with a length interval of 16 and calculate the specific time required.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create the generator instance\ngenerator = Generator(symbol_params=SymbolParams(max_trials=16))\n\n# The number of generated data\ntry_count = 1\n\nlength_array = np.arange(16, 528, 16)\n\ntime_array = np.zeros_like(length_array)\n\n# Variables with different time lengths\nfor index, n_points in enumerate(length_array):\n    start = time.time()\n    for seed in tqdm(range(try_count)):\n        # Create the random number generator\n        rng = np.random.RandomState(seed)\n\n        # Start generating data\n        generator.run(\n            rng=rng, input_dimension=1, output_dimension=1, n_inputs_points=n_points\n        )\n\n    # Record the time required for this length\n    end = time.time()\n    time_array[index] = end - start\n\n    # Print status information\n    print(f\"Generate Length: {n_points}, Time: {end - start}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above experimental results, we can generally see that the time required for data generation is generally proportional to the length of the time series.\nHowever, consider that in many cases, when we construct the symbolic expression $f(\\cdot)$ and input the stimulus time series $X$ into the system to obtain the corresponding $Y=f(X)$, the values \u200b\u200bof the stimulus time series may fall outside the domain of the symbolic expression $f(\\cdot)$, resulting in sampling failure. This phenomenon will affect the sampling time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n\nfig, ax = plt.subplots(figsize=(8, 3), dpi=180)\n\nax.plot(\n    length_array,\n    time_array,\n    color=\"royalblue\",\n    marker=\"o\",\n    markersize=5,\n    markerfacecolor=\"white\",\n)\nax.grid(\"--\", color=\"gray\", alpha=0.4)\nax.set_xlabel(\"The length of the generated time series\", fontsize=12)\nax.set_ylabel(\"The Time Complexity Analysis\", fontsize=12)\n\n# %%"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}